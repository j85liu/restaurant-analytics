{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e57cdf",
   "metadata": {},
   "source": [
    "## Restaurant Practice 2 ##\n",
    "\n",
    "Dataset: restaurant_transactions.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a010997",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Import Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be8223c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (3078, 23)\n",
      "   TransactionID CustomerID   Restaurant  Location       Date      Time  \\\n",
      "0          10001   CUST0093     TacoTime   Chicago 2024-11-02  11:18:00   \n",
      "1          10002   CUST0089      PizzaCo  New York 2024-11-02  13:27:00   \n",
      "2          10003   CUST0092     TacoTime   Houston 2024-11-02  18:34:00   \n",
      "3          10004   CUST0014  BurgerPlace   Houston 2024-11-02  12:15:00   \n",
      "4          10005   CUST0089      PizzaCo  New York 2024-11-02  12:10:00   \n",
      "\n",
      "    OrderType PaymentMethod  \\\n",
      "0     Dine-in     Gift Card   \n",
      "1    Delivery          Cash   \n",
      "2     Dine-in    Mobile App   \n",
      "3     Takeout   Credit Card   \n",
      "4  Drive-thru   Credit Card   \n",
      "\n",
      "                                        ItemsOrdered  Subtotal  ...  \\\n",
      "0                         Beans, Quesadilla, Burrito     19.47  ...   \n",
      "1  Veggie Pizza, Chicken Wings, Meat Lovers Pizza...     51.96  ...   \n",
      "2                                 Beef Taco, Burrito     12.98  ...   \n",
      "3                                       Cheeseburger      8.99  ...   \n",
      "4                   Cheese Pizza, Soda, Veggie Pizza     31.47  ...   \n",
      "\n",
      "   DeliveryFee  Total  ProcessingTimeMin  EmployeeID  Weather  PromotionCode  \\\n",
      "0         0.00  19.77               38.0      EMP012    Clear        LOYALTY   \n",
      "1         3.19  57.10               28.0      EMP025    Clear            NaN   \n",
      "2         0.00  16.82               44.0      EMP006    Sunny            NaN   \n",
      "3         0.00   9.73               17.0      EMP026    Clear            NaN   \n",
      "4         0.00  34.07                9.0      EMP010    Sunny           BOGO   \n",
      "\n",
      "  SatisfactionRating TransactionType RefundReason  OriginalTransactionID  \n",
      "0                4.0        Purchase          NaN                    NaN  \n",
      "1                NaN        Purchase          NaN                    NaN  \n",
      "2                2.0        Purchase          NaN                    NaN  \n",
      "3                5.0        Purchase          NaN                    NaN  \n",
      "4                NaN        Purchase          NaN                    NaN  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "## Step 2: Load Data\n",
    "\n",
    "df = pd.read_excel(\"restaurant_transactions.xlsx\")\n",
    "\n",
    "print(f\"Shape of data: {df.shape}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e320267a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Types: \n",
      "TransactionID                     int64\n",
      "CustomerID                       object\n",
      "Restaurant                       object\n",
      "Location                         object\n",
      "Date                     datetime64[ns]\n",
      "Time                             object\n",
      "OrderType                        object\n",
      "PaymentMethod                    object\n",
      "ItemsOrdered                     object\n",
      "Subtotal                        float64\n",
      "Discount                        float64\n",
      "Tax                             float64\n",
      "Tip                             float64\n",
      "DeliveryFee                     float64\n",
      "Total                           float64\n",
      "ProcessingTimeMin               float64\n",
      "EmployeeID                       object\n",
      "Weather                          object\n",
      "PromotionCode                    object\n",
      "SatisfactionRating              float64\n",
      "TransactionType                  object\n",
      "RefundReason                     object\n",
      "OriginalTransactionID           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Types: \")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3061a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransactionID               0\n",
      "CustomerID                  0\n",
      "Restaurant                  0\n",
      "Location                    0\n",
      "Date                        0\n",
      "Time                        0\n",
      "OrderType                   0\n",
      "PaymentMethod               0\n",
      "ItemsOrdered                0\n",
      "Subtotal                    0\n",
      "Discount                    0\n",
      "Tax                         0\n",
      "Tip                         0\n",
      "DeliveryFee                 0\n",
      "Total                       0\n",
      "ProcessingTimeMin          11\n",
      "EmployeeID                 10\n",
      "Weather                     9\n",
      "PromotionCode            2497\n",
      "SatisfactionRating       2067\n",
      "TransactionType             0\n",
      "RefundReason             2917\n",
      "OriginalTransactionID    2917\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eaefb77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique Restaurants: \n",
      "['TacoTime' 'PizzaCo' 'BurgerPlace' 'SandwichShop' 'BurgerPlace.'\n",
      " 'Pizza Co' 'Pizza Co.' 'Burger Place' 'Burger_Place' 'PizzaCo.']\n",
      "\n",
      "Unique Payment Methods:\n",
      "['Gift Card' 'Cash' 'Mobile App' 'Credit Card' 'Debit Card' 'GIFT CARD'\n",
      " 'credit card' 'gift card' 'cash' 'MOBILE APP' 'mobile app' 'CASH'\n",
      " 'debit card' 'DEBIT CARD' 'CREDIT CARD']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUnique Restaurants: \")\n",
    "print(df['Restaurant'].unique())\n",
    "print(\"\\nUnique Payment Methods:\")\n",
    "print(df['PaymentMethod'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb880756",
   "metadata": {},
   "source": [
    "# Data Quality Issues Added\n",
    "\n",
    "This updated code includes several realistic data quality issues that you'll need to clean:\n",
    "\n",
    "1. **Refund Transactions**:\n",
    "   * Added refund transactions (about 5% of transactions) with negative amounts\n",
    "   * Linked to original transactions via OriginalTransactionID\n",
    "   * Only applied to credit card transactions\n",
    "\n",
    "2. **Inconsistent Formatting**:\n",
    "   * Restaurant names have variations (e.g., \"PizzaCo\", \"Pizza Co\", \"Pizza Co.\")\n",
    "   * Payment methods have inconsistent capitalization\n",
    "\n",
    "3. **Missing Values**:\n",
    "   * Some rows have NULL values for Weather, EmployeeID, or ProcessingTimeMin\n",
    "\n",
    "4. **Duplicate Transactions**:\n",
    "   * About 1% of transactions are duplicated with new transaction IDs\n",
    "\n",
    "5. **Calculation Errors**:\n",
    "   * Some refund transactions have slight discrepancies between components and totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c4896e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant\n",
      "PizzaCo         821\n",
      "TacoTime        792\n",
      "SandwichShop    746\n",
      "BurgerPlace     688\n",
      "Burger Place      9\n",
      "Pizza Co          7\n",
      "BurgerPlace.      5\n",
      "Pizza Co.         4\n",
      "Burger_Place      4\n",
      "PizzaCo.          2\n",
      "Name: count, dtype: int64\n",
      "Restaurant\n",
      "PizzaCo         834\n",
      "TacoTime        792\n",
      "SandwichShop    746\n",
      "BurgerPlace     706\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Clean Data\n",
    "\n",
    "# 3a: Standardize restaurant names\n",
    "print(df['Restaurant'].value_counts())\n",
    "\n",
    "# Create mapping dictionary\n",
    "restaurant_mapping = {\n",
    "    \"Pizza Co\" : \"PizzaCo\",\n",
    "    \"Pizza Co.\" : \"PizzaCo\",\n",
    "    'PizzaCo.' : 'PizzaCo',\n",
    "    'Burger Place' : 'BurgerPlace',\n",
    "    'BurgerPlace.' : 'BurgerPlace',\n",
    "    'Burger_Place' : 'BurgerPlace'\n",
    "}\n",
    "\n",
    "df['Restaurant'] = df['Restaurant'].replace(restaurant_mapping)\n",
    "\n",
    "print(df['Restaurant'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "837e9f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaymentMethod\n",
      "Credit Card    711\n",
      "Debit Card     619\n",
      "Cash           566\n",
      "Gift Card      562\n",
      "Mobile App     529\n",
      "gift card       15\n",
      "credit card     14\n",
      "GIFT CARD       11\n",
      "MOBILE APP      10\n",
      "CREDIT CARD      9\n",
      "debit card       8\n",
      "mobile app       7\n",
      "CASH             7\n",
      "cash             5\n",
      "DEBIT CARD       5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "After replacement: \n",
      "PaymentMethod\n",
      "Credit Card    734\n",
      "Debit Card     632\n",
      "Gift Card      588\n",
      "Cash           578\n",
      "Mobile App     546\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3b: normalize payment methods\n",
    "print(df['PaymentMethod'].value_counts())\n",
    "\n",
    "payment_mapping = {\n",
    "    'gift card' : 'Gift Card',\n",
    "    'credit card' : 'Credit Card',\n",
    "    'GIFT CARD' : 'Gift Card',\n",
    "    'MOBILE APP' : 'Mobile App',\n",
    "    'CREDIT CARD' : 'Credit Card',\n",
    "    'debit card' : 'Debit Card',\n",
    "    'mobile app' : 'Mobile App',\n",
    "    'CASH' : 'Cash',\n",
    "    'cash' : 'Cash',\n",
    "    'DEBIT CARD' : 'Debit Card'\n",
    "}\n",
    "\n",
    "df['PaymentMethod'] = df['PaymentMethod'].replace(payment_mapping)\n",
    "print(\"\\nAfter replacement: \")\n",
    "print(df['PaymentMethod'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7e22098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values: ['ProcessingTimeMin', 'EmployeeID', 'Weather', 'PromotionCode', 'SatisfactionRating', 'RefundReason', 'OriginalTransactionID']\n",
      "Filled missing weather with most common weather:  Sunny\n",
      "Filled missing employee ID with Unknown\n",
      "Filled Missing processing time for Dine-in with: 29.0\n",
      "Filled Missing processing time for Delivery with: 42.0\n",
      "Filled Missing processing time for Takeout with: 16.0\n",
      "Filled Missing processing time for Drive-thru with: 9.0\n"
     ]
    }
   ],
   "source": [
    "# 3c: Missing values\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "print(f\"Columns with missing values: {missing_cols}\")\n",
    "\n",
    "# Strategy for missing values\n",
    "if 'Weather' in missing_cols:\n",
    "    # Fill in missing weather with most common weather\n",
    "    most_common_weather = df['Weather'].mode()[0]\n",
    "    df['Weather'] = df['Weather'].fillna(most_common_weather)\n",
    "    print('Filled missing weather with most common weather: ', most_common_weather)\n",
    "\n",
    "if 'EmployeeID' in missing_cols:\n",
    "    # Fill in missing employee ID with Unknown\n",
    "    df['EmployeeID'] = df['EmployeeID'].fillna('Unknown')\n",
    "    print(\"Filled missing employee ID with Unknown\")\n",
    "\n",
    "if 'ProcessingTimeMin' in missing_cols:\n",
    "    # Fill in processing tiime with median based on order type\n",
    "    for order_type in df['OrderType'].unique():\n",
    "        median_processing_time = df[df['OrderType'] ==order_type]['ProcessingTimeMin'].median()\n",
    "        df.loc[(df['OrderType'] == order_type) & \n",
    "               (df['ProcessingTimeMin'].isnull()), 'ProcessingTimeMin'] = median_processing_time\n",
    "        print(f\"Filled Missing processing time for {order_type} with: {median_processing_time}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec6ca656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of potential duplicate transaction groups: 30\n",
      "Number of marked duplicate transactions: 30\n",
      "Shape after removing duplicates: (3048, 25)\n"
     ]
    }
   ],
   "source": [
    "# 3d: remove duplicates\n",
    "\n",
    "# Consider transactions as duplicates if they have the same customer, restaurant,\n",
    "# date, time, order type, items ordered, and total amount, but different transaction IDs\n",
    "potential_duplicate_columns = [\n",
    "    'CustomerID', 'Restaurant', 'Date', 'Time', 'OrderType', \n",
    "    'ItemsOrdered', 'Total'\n",
    "]\n",
    "\n",
    "# Create temp identifier for potential duplicates\n",
    "df['DuplicateGroup'] = df[potential_duplicate_columns].apply(tuple, axis=1)\n",
    "\n",
    "# Find duplicate groups\n",
    "duplicate_groups = df['DuplicateGroup'].value_counts()\n",
    "duplicate_groups = duplicate_groups[duplicate_groups > 1]\n",
    "\n",
    "print(f\"Number of potential duplicate transaction groups: {len(duplicate_groups)}\")\n",
    "\n",
    "if len(duplicate_groups) > 0:\n",
    "    # Mark duplicates, keeping the first occurrence\n",
    "    df['IsDuplicate'] = False\n",
    "    \n",
    "    for group in duplicate_groups.index:\n",
    "        group_df = df[df['DuplicateGroup'] == group]\n",
    "        duplicated_indices = group_df.index[1:]  # Keep the first one\n",
    "        df.loc[duplicated_indices, 'IsDuplicate'] = True\n",
    "    \n",
    "    print(f\"Number of marked duplicate transactions: {df['IsDuplicate'].sum()}\")\n",
    "    \n",
    "    \n",
    "    # Remove duplicates\n",
    "    df_cleaned = df[~df['IsDuplicate']]\n",
    "    print(f\"Shape after removing duplicates: {df_cleaned.shape}\")\n",
    "\n",
    "# Drop the temporary column\n",
    "df = df.drop('DuplicateGroup', axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "528ce652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of transactions with total discrepancies: 24\n",
      "\n",
      "Sample of transactions with discrepancies:\n",
      "      TransactionID  Total  ExpectedTotal  TotalDifference TransactionType\n",
      "69            10070 -32.01         -32.07             0.06          Refund\n",
      "205           10206 -35.40         -35.28            -0.12          Refund\n",
      "218           10219 -34.60         -34.07            -0.53          Refund\n",
      "350           10351 -22.97         -23.15             0.18          Refund\n",
      "363           10364 -33.74         -34.07             0.33          Refund\n",
      "374           10375 -29.45         -29.77             0.32          Refund\n",
      "455           10456 -47.51         -47.75             0.24          Refund\n",
      "564           10565  -7.96          -8.10             0.14          Refund\n",
      "600           10601 -23.76         -23.74            -0.02          Refund\n",
      "705           10706 -34.35         -34.61             0.26          Refund\n",
      "996           10997  -8.35          -8.42             0.07          Refund\n",
      "1309          11310 -22.22         -22.47             0.25          Refund\n",
      "1819          11820 -47.22         -47.05            -0.17          Refund\n",
      "1837          11838 -27.82         -28.11             0.29          Refund\n",
      "1989          11990 -14.54         -14.26            -0.28          Refund\n",
      "2078          12079 -36.07         -36.22             0.15          Refund\n",
      "2183          12184 -13.49         -13.24            -0.25          Refund\n",
      "2270          12271 -29.86         -29.40            -0.46          Refund\n",
      "2515          12516  -5.21          -5.26             0.05          Refund\n",
      "2524          12525 -19.16         -19.44             0.28          Refund\n",
      "2682          12683 -46.60         -46.50            -0.10          Refund\n",
      "2724          12725 -31.61         -31.35            -0.26          Refund\n",
      "2862          12863 -37.68         -37.97             0.29          Refund\n",
      "3058          13059  -8.35          -8.42             0.07          Refund\n",
      "\n",
      "Discrepancies correctd\n",
      "\n",
      "Remaining discrepancies: 0\n"
     ]
    }
   ],
   "source": [
    "# 3e: validate transaction totals (check if total = subtotal - discount + tax + tip + delivery fee)\n",
    "\n",
    "df['ExpectedTotal'] = (df['Subtotal'] - df['Discount'] + df['Tax'] + df['Tip'] + df['DeliveryFee']).round(2)\n",
    "\n",
    "df['TotalDifference'] = (df['Total'] - df['ExpectedTotal']).round(2)\n",
    "\n",
    "discrepancies = df[abs(df['TotalDifference']) > 0.01]\n",
    "print(f\"Number of transactions with total discrepancies: {len(discrepancies)}\")\n",
    "\n",
    "if len(discrepancies) > 0:\n",
    "    print(\"\\nSample of transactions with discrepancies:\")\n",
    "    print(discrepancies[['TransactionID', 'Total', 'ExpectedTotal', 'TotalDifference', 'TransactionType']])\n",
    "\n",
    "    # Correct discrepancies\n",
    "    df.loc[abs(df['TotalDifference']) > 0.01, 'Total'] = df['ExpectedTotal']\n",
    "    print(\"\\nDiscrepancies correctd\")\n",
    "\n",
    "# Recalculate the difference after corrections\n",
    "df['NewTotalDifference'] = (df['Total'] - df['ExpectedTotal']).round(2)\n",
    "# Check if any discrepancies remain\n",
    "remaining_discrepancies = df[abs(df['NewTotalDifference']) > 0.01]\n",
    "print(f\"\\nRemaining discrepancies: {len(remaining_discrepancies)}\")\n",
    "\n",
    "df = df.drop(['ExpectedTotal', 'TotalDifference', 'NewTotalDifference'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "deeead8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of refund transactions: 161\n",
      "    TransactionID  Total  OriginalTransactionID\n",
      "53          10054  -7.17                10027.0\n",
      "62          10063 -17.45                10043.0\n",
      "69          10070 -32.07                10016.0\n",
      "87          10088 -37.02                10033.0\n",
      "91          10092 -13.24                10050.0\n",
      "\n",
      "Refunds with links to original transactions: 161\n",
      "\n",
      "Payment methods for refunds: ['Credit Card']\n",
      "Removed 0 refund transactions\n",
      "Removed 161 original transactions that were refunded\n",
      "Dataset size after: 2799\n"
     ]
    }
   ],
   "source": [
    "# 3f: handle refunds\n",
    "refunds = df[df['Total'] < 0]\n",
    "print(f\"Number of refund transactions: {len(refunds)}\")\n",
    "\n",
    "print(refunds[['TransactionID', 'Total', 'OriginalTransactionID']].head())\n",
    "\n",
    "# Check if refunds are linked to orig transactions\n",
    "linked_refunds = refunds[refunds['OriginalTransactionID'].notna()]\n",
    "print(f\"\\nRefunds with links to original transactions: {len(linked_refunds)}\")\n",
    "\n",
    "payment_methods_for_refunds = refunds['PaymentMethod'].unique()\n",
    "print(f\"\\nPayment methods for refunds: {payment_methods_for_refunds}\")\n",
    "\n",
    "# Add a flag column to easily identify refunds in analysis\n",
    "df['IsRefund'] = df['TransactionType'] == 'Refund'\n",
    "\n",
    "# remove refunds\n",
    "\n",
    "# Get IDs of original transactions that were refunded\n",
    "original_ids = df[df['IsRefund']]['OriginalTransactionID'].tolist()\n",
    "\n",
    "# Filter out both refunds and their original transactions\n",
    "df = df[~(df['IsRefund'] | df['TransactionID'].isin(original_ids))].copy()\n",
    "\n",
    "# Print summary of removals\n",
    "print(f\"Removed {df['IsRefund'].sum()} refund transactions\")\n",
    "print(f\"Removed {len(original_ids)} original transactions that were refunded\")\n",
    "print(f\"Dataset size after: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6de5c532",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/31/b1v52j156gbfz83pmrnth3jc0000gn/T/ipykernel_69396/138550983.py:17: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Hour'] = pd.to_datetime(df['Time'].astype(str)).dt.hour\n"
     ]
    }
   ],
   "source": [
    "# Convert Date and Time Columns\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Create a datetime column combining date and time\n",
    "df['DateTime'] = pd.to_datetime(\n",
    "    df['Date'].dt.strftime('%Y-%m-%d') + ' ' + \n",
    "    df['Time'].astype(str),\n",
    "    errors='coerce'  # Handle any conversion errors\n",
    ")\n",
    "\n",
    "# Extract useful components\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['DayOfWeek'] = df['Date'].dt.day_name()\n",
    "df['Hour'] = pd.to_datetime(df['Time'].astype(str)).dt.hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f48d0e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved with 2799 rows and 31 columns.\n"
     ]
    }
   ],
   "source": [
    "# Save Cleaned Data\n",
    "\n",
    "# Save the cleaned data to a new file\n",
    "df.to_excel('restaurant_transactions_cleaned.xlsx', index=False)\n",
    "print(f\"Cleaned data saved with {len(df)} rows and {len(df.columns)} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ccd49244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final data quality check:\n",
      "Missing values after cleaning: 9738\n",
      "Unique restaurant names: ['TacoTime' 'PizzaCo' 'SandwichShop' 'BurgerPlace']\n",
      "Unique payment methods: ['Gift Card' 'Cash' 'Mobile App' 'Credit Card' 'Debit Card']\n",
      "Refund transactions: 0\n",
      "\n",
      "Summary statistics after cleaning:\n",
      "              count       sum       mean  median\n",
      "Restaurant                                      \n",
      "BurgerPlace     662  14949.64  22.582538  21.625\n",
      "PizzaCo         752  25646.24  34.104043  33.510\n",
      "SandwichShop    685  13017.10  19.003066  18.260\n",
      "TacoTime        700  10417.50  14.882143  14.040\n",
      "(2799, 31)\n"
     ]
    }
   ],
   "source": [
    "# Verify the cleaning was successful\n",
    "print(\"\\nFinal data quality check:\")\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"Missing values after cleaning: {df.isnull().sum().sum()}\")\n",
    "print(f\"Unique restaurant names: {df['Restaurant'].unique()}\")\n",
    "print(f\"Unique payment methods: {df['PaymentMethod'].unique()}\")\n",
    "print(f\"Refund transactions: {df['IsRefund'].sum()}\")\n",
    "\n",
    "# Basic summary stats on key metrics\n",
    "print(\"\\nSummary statistics after cleaning:\")\n",
    "print(df.groupby('Restaurant')['Total'].agg(['count', 'sum', 'mean', 'median']))\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a8ff5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
